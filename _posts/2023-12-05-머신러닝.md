---
layout: post
title: 머신러닝 정리
date: 2023-12-05 11:53 +0900 
description: 머신러닝 정리
category: [AI, 머신러닝]
tags: [AI, 머신러닝, DNN, RNN, CNN] # 문제유형
pin: false
math: true
mermaid: true
---
4-2학기 머신러닝 프로젝트를 듣고나서
<!--more-->


## 지능이란?


대부분의 사전에서는 지적능력을 의미한다. 위키백과에는 다음과 같이 정의한다. “지능은 심리학적으로 대상이나 상황에 부딪혀 그 의미를 이해하고 합리적인 적응 방법을 알아내는 지적 활동의 능력”. 해석하기 힘든 말이다. 이것보다 더 나은 정의를 찾아보니 “새로운 상황을 분석 및 이해하기 위해 사전 지식을 활용하는 것”이라는 표현이 있었다. 이부분이 더 와닿는 것 같다. 결국 지능의 원천은 ‘기억’이다. 학습을 통해 우리는 배우고 이를 기억한다.


경험 및 학습으로 얻은 내용을 통해 우리는 추리한다. 인공지능도 똑같다. 데이터를 통한 연산으로 학습하고, 이를 기억(모델링)한다. 


### 사람의 학습과정


그렇다면 어떻게 학습할까?


우리가 학습하는 과정을 먼저 살펴본다.

1. 추상화

우리는 여러가지 물리적 객체를 보고, 이를 추상화하여 속성을 추출한다. 이를 통해 우리는 나무를 보며 뿌리와 잎, 줄기 3부분으로 이뤄진 것을 알 수 있다.


추상화 과정을 통해, 독특한 나무를 봐도(뿌리, 줄기, 잎이 있다면) 나무라고 인식할 수 있게된다.


죽, 물체를 보고 추상화를 통해 대상의 특성을 추출한다. 추출된 특성을 기반으로 새로운 물체가 들어오면 판단할 수 있다.


## 머신러닝 학습 과정


1차원의 데이터를 식별할 때는, 간단하게 기준점을 잡으면된다. 예를 들어, 사람의 키로 성별을 구분한다고 하면 약 170정도가 아마 기준점이 될 것이다. 하지만, 간단한 문제라면 정확도가 높을 수 있지만 어려운 문제는 1차원의 데이터로 해결할 수 없다.


문제가 어려울 수록 차원을 확장하여 해결하려고 노력한다. 키와 몸무게로 성별을 구분하면, 이전보다 더 나은 결과를 얻을 수 있다. 하지만, 그렇다고 무작정 차원을 늘린다면 어느 순간보다 정확도는 훨씬 낮아질 것이다. 도움이 되는 특성이 있는 반면, 더 헷갈리게 할 수 있다.


또한, 이런 선형분리는 XOR과 같은 문제를 해결할 수 없다. 


![http://programmermagazine.github.io/201404/book/pmag.html](/assets/img/post/머신러닝/1.png)



이런 경우는 차원을 늘려 해결하거나, 아래와 같이 입력의 형태를 변환하여 해결한다. 


![http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/](/assets/img/post/머신러닝/2.png)


### 학습 방법


이제 데이터를 통해 모델이 학습하는 방법에 대해 알아보자. 그전에 비용함수를 알아야한다. 비용함수는 모델의 가중치(현 기준)에 의해 발생되는 오차의 정도이다. 학습알고리즘은 비용함수를 기반으로 작동한다. 


가장 대표적인 알고리즘은 경사 하강법(Gradient Descent)이다. 비용함수의 기울기를 확인하고, 극값(기울기 = 0) 쪽으로 이동하며 점점 오차를 줄인다.


![Untitled.png](/assets/img/post/머신러닝/3.png)


### 퍼셉트론


사람의 신경세포 동작과정을 흉내낸 모델이 퍼셉트론이다. 


![https://compmath.korea.ac.kr/deeplearning/Perceptron.html](/assets/img/post/머신러닝/4.png)


각 입력에 가중치를 적용한 뒤, 이를 합쳐 결과를 도출한다. 하지만 단일층으로는 위에서 언급한 XOR 문제를 해결하지 못해, 다중 신경망을 적용한다.


[링크](http://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2,2&seed=0.23199&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)를 통해 아래와 같이 데이터 셋에 대한, 다중 신경망 체험을 할 수 있다.


![Untitled.png](/assets/img/post/머신러닝/5.png)


## CNN


CNN은 합성곱 신경망으로, 이미지처리에 뛰어난 성능을 보인다. Conv와 pooling을 반복한다. 


![https://sites.google.com/site/nttrungmtwiki/home/it/deep-learning/convolution-neural-network/understanding-convolutional-neural-networks-for-nlp](/assets/img/post/머신러닝/6.png)


### **Convolution Filter**


특정 모양에 반응하는 신경세포들이 있듯이, CNN도 이미지에서 특정 데이터를 추출하려고 노력한다.


![https://developer.apple.com/documentation/accelerate/blurring_an_image](/assets/img/post/머신러닝/7.png)


필터 모양에 따라, 추출되는 결과값에 특정 패턴이 도드라진다. 아래는 왼쪽상단에서 시작하는 대각선에 초점을 맞춘 필터로, 추후 결과에서도 필터와 유사한 패턴이 도드라진다.


![http://www.kdnuggets.com/2016/08/brohrer-convolutional-neural-networks-explanation.html](/assets/img/post/머신러닝/8.png)


### Pooling


풀링은 단순하게, 이미지(픽셀)을 줄이는 것이다. 아래의 예시는 MAX Pooling이다. 각 위치의 최댓값만 가져와 이미지를 줄인다.


![Untitled.png](/assets/img/post/머신러닝/9.png)


## 순환 신경망(RNN)


재귀, 순환, 직렬 신경망으로 불리는 RNN은 순차데이터나 시계열데이터를 이용하는 인공 신경망이다. 이는 아래의 마르코프 모델에서 아이디어를 가져와 기존 퍼셉트론 모델(DNN)과 다르게 상태를 가지고 있는다.


### **Markov** Model


마르코프 모델, 마르코프 특성이란 n+1 단계에서 상태는 n 단계의 상태에만 영향을 받는 것을 의미한다. 즉, 이전 단계의 결과가 현재 단계에 영향을 미친다. 


![https://mbounthavong.com/blog/2018/3/15/generating-survival-curves-from-study-data-an-application-for-markov-models-part-2-of-2)](/assets/img/post/머신러닝/10.png)


위의 사이트에는 마르코프 모델에 대한 간단한 예시가 작성되어있다.


healthy은 자기자신, sick, dead에게 영향을 준다. 하지만 Dead는 Dead에게만 영향을 준다. 이처럼 각 단계가 서로에게 영향을 주는 것이 마르코프 모델이다.


![Untitled.png](/assets/img/post/머신러닝/11.png)

![Untitled.png](/assets/img/post/머신러닝/12.png)


위의 상태를 확인해보면, 이전과는 다르게 과거의 상태가 다음 상태에 영향을 미친다. 이를 수식으로 나타내면 다음과 같다. $s_{t} = f_{m}(s_{t-1}x_{t})$ 이를 통해 "feeling under the weather(몸이 좋지 않다)”와 같은 자연어와 같은 처리가 가능해진다. 즉, 이제 들어오는 순서가 중요한 데이터를 분류할 수 있게된다.


**BPTT(Backpropagation Through Time)**는 RNN을 학습시키는 알고리즘이다. [링크](http://solarisailab.com/archives/1451)에 자세하게 설명되어있다. 간단하게 설명하면, 얼정 시간의 에러 값을 합하여 역전파한다. 이로 인해 V(은닉층)과 U(순환) 가중치를 업데이트 할 수 있다. 

